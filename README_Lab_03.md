
# –õ–†3 ‚Äî –¢–µ–∫—Å—Ç—ã –∏ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ (—Å–ª–æ–≤–∞—Ä—å/–º–Ω–æ–∂–µ—Å—Ç–≤–æ)

> **–¶–µ–ª—å:** –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ç–æ–ø-N.  
> **–°–≤—è–∑—å:** –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –õ–†2 (—Ä–∞–±–æ—Ç–∞ —Å–æ —Å–ø–∏—Å–∫–∞–º–∏) –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –õ–†4 (—Ñ–∞–π–ª—ã) ‚Äî –º–æ–¥—É–ª—å `lib/text.py` –±—É–¥–µ–º –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.

---

## –†–µ–∑—É–ª—å—Ç–∞—Ç –õ–†
- –ú–æ–¥—É–ª—å `src/lib/text.py` —Å —á–∏—Å—Ç—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏: `normalize`, `tokenize`, `count_freq`, `top_n`.  
- –°–∫—Ä–∏–ø—Ç `src/lab03/text_stats.py`, —á–∏—Ç–∞—é—â–∏–π –≤—Ö–æ–¥ –∏–∑ **stdin** –∏ –ø–µ—á–∞—Ç–∞—é—â–∏–π –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.  
- README —Å **–∫–æ–¥–æ–º** –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞, –ø—Ä–∏–º–µ—Ä–∞–º–∏ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏ –∑–∞–ø—É—Å–∫–∞.  
- **–¢–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞** (–Ω–∏–∫–∞–∫–∏—Ö NLTK –∏ —Ç.–ø.). Python **3.—Ö—Ö+**.

---

## –ó–∞–¥–∞–Ω–∏–µ A ‚Äî `src/lib/text.py`

–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏:

1. `normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str`  
   - –ï—Å–ª–∏ `casefold=True` ‚Äî –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ **casefold** (–ª—É—á—à–µ, —á–µ–º `lower` –¥–ª—è –Æ–Ω–∏–∫–æ–¥–∞).  
   - –ï—Å–ª–∏ `yo2e=True` ‚Äî –∑–∞–º–µ–Ω–∏—Ç—å –≤—Å–µ `—ë`/`–Å` –Ω–∞ `–µ`/`–ï`.  
   - –£–±—Ä–∞—Ç—å –Ω–µ–≤–∏–¥–∏–º—ã–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, `\t`, `\r`) ‚Üí –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ–±–µ–ª—ã, —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –≤ –æ–¥–∏–Ω.

2. `tokenize(text: str) -> list[str]`  
   - –†–∞–∑–±–∏—Ç—å –Ω–∞ ¬´—Å–ª–æ–≤–∞¬ª –ø–æ –Ω–µ–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º.  
   - –í –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–æ–≤–∞ —Å—á–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤ `\w` (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ) **–ø–ª—é—Å** –¥–µ—Ñ–∏—Å –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É`).  
   - –ß–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `2025`) —Å—á–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞–º–∏.

3. `count_freq(tokens: list[str]) -> dict[str, int]`  
   - –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—ã, –≤–µ—Ä–Ω—É—Ç—å —Å–ª–æ–≤–∞—Ä—å `—Å–ª–æ–≤–æ ‚Üí –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ`.

4. `top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]`  
   - –í–µ—Ä–Ω—É—Ç—å —Ç–æ–ø-N –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã; –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É —Å–ª–æ–≤–∞.

### –¢–µ—Å—Ç-–∫–µ–π—Å—ã

**normalize**
- `"–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"` ‚Üí `"–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"` (casefold + —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø—Ä–æ–±–µ–ª—ã)  
- `"—ë–∂–∏–∫, –Å–ª–∫–∞"` (`yo2e=True`) ‚Üí `"–µ–∂–∏–∫, –µ–ª–∫–∞"`  
- `"Hello\r\nWorld"` ‚Üí `"hello world"`  
- `"  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "` ‚Üí `"–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"`

**tokenize** *(–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç —É–∂–µ normalize)*
- `"–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"` ‚Üí `["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]`  
- `"hello,world!!!"` ‚Üí `["hello", "world"]`  
- `"–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"` ‚Üí `["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]`  
- `"2025 –≥–æ–¥"` ‚Üí `["2025", "–≥–æ–¥"]`  
- `"emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"` ‚Üí `["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]` (—ç–º–æ–¥–∑–∏ –≤—ã–ø–∞–¥–∞—é—Ç)

**count_freq + top_n**
- –¢–æ–∫–µ–Ω—ã `["a","b","a","c","b","a"]` ‚Üí —á–∞—Å—Ç–æ—Ç—ã `{"a":3,"b":2,"c":1}`;  
  `top_n(..., n=2)` ‚Üí `[("a",3), ("b",2)]`  
- –ü—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —á–∞—Å—Ç–æ—Ç: —Ç–æ–∫–µ–Ω—ã `["bb","aa","bb","aa","cc"]` ‚Üí —á–∞—Å—Ç–æ—Ç—ã `{"aa":2,"bb":2,"cc":1}`;  
  `top_n(..., n=2)` ‚Üí `[("aa",2), ("bb",2)]` (–∞–ª—Ñ–∞–≤–∏—Ç–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ).

---

*Code*

```

import re
from typing import Dict, List, Tuple

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True):
    if not text:
        return ""
    
    result = text
    
    if yo2e:
        result = result.replace('—ë', '–µ').replace('–Å', '–ï')
    
    if casefold:
        result = result.casefold()
    
    control_chars = {'\\t', '\\r', '\\n'}
    for char in control_chars:
        result = result.replace(char, ' ')
    
    result = re.sub(r'\s+', ' ', result).strip()
    
    return result


def tokenize(text: str):
    if not text:
        return []
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    
    return tokens


def count_freq(tokens: List[str]):
    freq_dict = {}
    
    for token in tokens:
        if not token or not any(c.isalpha() for c in token):
            continue
            
        freq_dict[token] = freq_dict.get(token, 0) + 1
    
    return freq_dict


#def top_n(freq: Dict[str, int], n: int = 5) -> List[Tuple[str, int]]:
    if not freq:
        return []
    
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    
    return sorted_items[:n]

def top_n(data, n: int = 5):
    freq = {}
    
    if isinstance(data, list):
        freq = count_freq(data)
    elif isinstance(data, dict):
        freq = data
    else:
        return []
    
    if not freq:
        return []
    
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    
    return sorted_items[:n]

x = int(input())

if x == 1:
    s = input()
    a = normalize(s)
    print(a)
elif x == 2:
    s = input()
    a = tokenize(s)
    print(a)
elif x == 3:
    s = input()
    a = count_freq(s)
    print(a)
elif x == 4:
    s = input()
    n = int(input())
    s_clean = s.strip('[]\"\'')
    items = [item.strip(' \"\'') for item in s_clean.split(',') if item.strip()]
    a = top_n(items, n)
    print(a)

```

*Screen*

<img width="495" height="397" alt="1" src="https://github.com/user-attachments/assets/e499e64e-fa64-49fb-9fa5-6c03409c4ab5" />
<img width="425" height="364" alt="2" src="https://github.com/user-attachments/assets/b0ccae31-dbcf-4f99-800c-8b6583d25bda" />
<img width="351" height="277" alt="3" src="https://github.com/user-attachments/assets/852287e5-e8bb-48ec-b017-7760b06c7198" />
<img width="442" height="356" alt="4" src="https://github.com/user-attachments/assets/7b26503c-0359-4595-9330-fbe1bf2b3c98" />

---

## –ó–∞–¥–∞–Ω–∏–µ B ‚Äî `src/text_stats.py` (—Å–∫—Ä–∏–ø—Ç —Å–æ stdin)

–°–∫—Ä–∏–ø—Ç —á–∏—Ç–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Ç–µ–∫—Å—Ç–∞ –∏–∑ **stdin** (–∏–ª–∏ –≤–µ—Å—å –≤–≤–æ–¥ –¥–æ EOF ‚Äî –Ω–∞ –≤–∞—à –≤—ã–±–æ—Ä, –æ–ø–∏—à–∏—Ç–µ –≤ README), –≤—ã–∑—ã–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ `lib/text.py` –∏ –ø–µ—á–∞—Ç–∞–µ—Ç:

1. `–í—Å–µ–≥–æ —Å–ª–æ–≤: <N>`  
2. `–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: <K>`  
3. `–¢–æ–ø-5:` ‚Äî –ø–æ —Å—Ç—Ä–æ–∫–µ –Ω–∞ –∑–∞–ø–∏—Å—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ `—Å–ª–æ–≤–æ:–∫–æ–ª-–≤–æ` (–ø–æ —É–±—ã–≤–∞–Ω–∏—é, –∫–∞–∫ –≤ `top_n`).

### –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞
–í —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:
```
$ echo "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!" | python src/text_stats.py
–í—Å–µ–≥–æ —Å–ª–æ–≤: 3
–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 2
–¢–æ–ø-5:
–ø—Ä–∏–≤–µ—Ç:2
–º–∏—Ä:1
```

--- 

*Code*

```

from lib.text import normalize, tokenize, count_freq, top_n

text = input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç: ")

normalized_text = normalize(text)
tokens = tokenize(normalized_text)

total_words = len(tokens)
unique_words = len(set(tokens))
freq = count_freq(tokens)
top_words = top_n(freq, 5)

print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
print("–¢–æ–ø-5 —Å–ª–æ–≤:")
for word, count in top_words:
    print(f"{word}: {count}")

```

*Screen*

<img width="569" height="422" alt="5" src="https://github.com/user-attachments/assets/5e8de5d3-2163-4d87-b75f-566baed60400" />

---

### –í—ã–≤–æ–¥:
–í –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç–µ ‚Ññ3 —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏. –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã 4 –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏: normalize() –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, tokenize() –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ —Å–ª–æ–≤–∞, count_freq() –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —á–∞—Å—Ç–æ—Ç –∏ top_n() –¥–ª—è –≤—ã–≤–æ–¥–∞ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤. –°–æ–∑–¥–∞–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ text_stats.py, –∫–æ—Ç–æ—Ä–∞—è —á–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ stdin –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –∏ —Ç–æ–ø-5 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤. –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞—Ö.
